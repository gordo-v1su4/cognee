# PostgreSQL Configuration
POSTGRES_DB=cognee
POSTGRES_USER=cognee
POSTGRES_PASSWORD=change_this_secure_password

# Neo4j Configuration
NEO4J_USER=neo4j
NEO4J_PASSWORD=change_this_secure_password
NEO4J_HTTP_PORT=7474
NEO4J_BOLT_PORT=7687
NEO4J_HEAP_SIZE=2G

# Qdrant Configuration
QDRANT_PORT=6333
QDRANT_API_KEY=

# Vector Database Provider (qdrant, pinecone, weaviate)
VECTOR_DB_PROVIDER=qdrant

# Graph Database Provider (neo4j, networkx)
GRAPH_DB_PROVIDER=neo4j

# LLM Provider Configuration
# Options: openai, anthropic, azure, ollama
LLM_PROVIDER=openai
LLM_API_KEY=your_openai_api_key_here
LLM_MODEL=gpt-4

# Embedding Provider Configuration
# Options: openai, sentence-transformers, azure
EMBEDDING_PROVIDER=openai
EMBEDDING_API_KEY=your_openai_api_key_here
EMBEDDING_MODEL=text-embedding-3-small

# Application Configuration
COGNEE_PORT=8000
COGNEE_ENV=production
LOG_LEVEL=INFO

# Domain Configuration (for Coolify deployment)
COGNEE_DOMAIN=cognee.v1su4.com
COGNEE_URL=https://cognee.v1su4.com

# Optional: Azure OpenAI Configuration
# AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/
# AZURE_OPENAI_API_KEY=your_azure_api_key
# AZURE_OPENAI_API_VERSION=2023-05-15

# Optional: Anthropic Configuration
# ANTHROPIC_API_KEY=your_anthropic_api_key

# Optional: Ollama Configuration (for local LLMs)
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=llama2

